{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97f4b4bb-6005-41cb-9c0a-c74a6fa41a33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Pure Spark :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49423ee1-f99a-4bb7-8300-5f53814f51d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"IntegralApproximation\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Function and interval\n",
    "a = 0  # Lower limit\n",
    "b = 4  # Upper limit\n",
    "n = 100000  # Number of intervals (higher = more accurate)\n",
    "\n",
    "dx = (b - a) / n  # Step size\n",
    "\n",
    "# Create RDD with n values from 0 to n-1\n",
    "rdd = sc.parallelize(range(n))\n",
    "\n",
    "# Use midpoint Riemann sum: x_i = a + (i + 0.5) * dx\n",
    "def f(x):\n",
    "    return x ** 2\n",
    "\n",
    "area = rdd.map(lambda i: f(a + (i + 0.5) * dx) * dx).sum()\n",
    "\n",
    "print(f\"Estimated integral of x^2 from {a} to {b} is: {area:.5f}\")\n",
    "\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02ae25d2-f45b-4528-8cfa-6bff3c516f53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "# Create Spark session (unnecessary in Databricks notebook)\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Parameters\n",
    "a = 0\n",
    "b = 4\n",
    "n = 100000\n",
    "dx = (b - a) / n\n",
    "\n",
    "# Create a DataFrame with values i = 0 to n-1\n",
    "df = spark.range(n)\n",
    "\n",
    "# Calculate midpoint x = a + (i + 0.5) * dx\n",
    "df = df.withColumn(\"x\", expr(f\"{a} + (id + 0.5) * {dx}\"))\n",
    "\n",
    "# Calculate f(x) = x^2 and area = f(x) * dx\n",
    "df = df.withColumn(\"fx\", col(\"x\") ** 2)\n",
    "df = df.withColumn(\"area\", col(\"fx\") * dx)\n",
    "\n",
    "# Sum the areas\n",
    "total_area = df.agg({\"area\": \"sum\"}).collect()[0][0]\n",
    "\n",
    "print(f\"Estimated integral: {total_area:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cadb2f1-a4e6-47db-9fd8-cd92d4ee82c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This part doesn't use session builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d55f84e-661f-4be6-8919-dab10d48e119",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "# Define integration parameters\n",
    "a = 0\n",
    "b = 4\n",
    "n = 100000\n",
    "dx = (b - a) / n\n",
    "\n",
    "# Use existing 'spark' session to create a DataFrame with values 0 to n-1\n",
    "df = spark.range(n)\n",
    "\n",
    "# Apply midpoint rule: x = a + (i + 0.5) * dx\n",
    "df = df.withColumn(\"x\", expr(f\"{a} + (id + 0.5) * {dx}\"))\n",
    "\n",
    "# Compute f(x) = x^2\n",
    "df = df.withColumn(\"fx\", col(\"x\") ** 2)\n",
    "\n",
    "# Area = f(x) * dx\n",
    "df = df.withColumn(\"area\", col(\"fx\") * dx)\n",
    "\n",
    "# Sum all areas to approximate the integral\n",
    "total_area = df.agg({\"area\": \"sum\"}).collect()[0][0]\n",
    "\n",
    "print(f\"Estimated integral of x^2 from 0 to 4: {total_area:.5f}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Riemann Integral",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

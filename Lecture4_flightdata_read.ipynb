{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PAm-nFU3r76skFlzm6_0kXSkEXSA91hB",
      "authorship_tag": "ABX9TyNDcHWeg0gxwTkDQ903naBH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hbisgin/BigDatav1/blob/main/Lecture4_flightdata_read.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFvenbSVu9dk",
        "outputId": "3f2c21dc-5227-4c58-9c2b-9dab4446d266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-05 17:17:16--  https://raw.githubusercontent.com/databricks/Spark-The-Definitive-Guide/refs/heads/master/data/flight-data/csv/2015-summary.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7080 (6.9K) [text/plain]\n",
            "Saving to: ‘2015-summary.csv’\n",
            "\n",
            "2015-summary.csv    100%[===================>]   6.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-09-05 17:17:16 (61.5 MB/s) - ‘2015-summary.csv’ saved [7080/7080]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/databricks/Spark-The-Definitive-Guide/refs/heads/master/data/flight-data/csv/2015-summary.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head /content/2015-summary.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-m4_IHbvrew",
        "outputId": "202e4e2d-8564-49fc-a03c-1532cea01d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEST_COUNTRY_NAME,ORIGIN_COUNTRY_NAME,count\n",
            "United States,Romania,15\n",
            "United States,Croatia,1\n",
            "United States,Ireland,344\n",
            "Egypt,United States,15\n",
            "United States,India,62\n",
            "United States,Singapore,1\n",
            "United States,Grenada,62\n",
            "Costa Rica,United States,588\n",
            "Senegal,United States,40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"flight\").getOrCreate()\n",
        "flightData2015 = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"/content/2015-summary.csv\")\n"
      ],
      "metadata": {
        "id": "K0BgvWsnvZYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flightData2015.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_qph9wR4nrv",
        "outputId": "49e71944-fcc7-4b3e-cc16-2792da18148d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flightData2015.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh-QdqLowpGD",
        "outputId": "1a32489c-0eac-4b85-b896-1078e5df9d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n",
              " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n",
              " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flightData2015.createOrReplaceTempView(\"flight_data_2015\")"
      ],
      "metadata": {
        "id": "TH1MTg5x5ODP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SQL-way"
      ],
      "metadata": {
        "id": "29OjjOoy5y1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sqlWay = spark.sql(\"\"\"\n",
        "SELECT DEST_COUNTRY_NAME, count(1)\n",
        "FROM flight_data_2015\n",
        "GROUP BY DEST_COUNTRY_NAME\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "bmjyn0H052LA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sqlWay.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z2LctubOGYS",
        "outputId": "9fd517be-67fa-4444-c26c-55297abe4f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+--------+\n",
            "|DEST_COUNTRY_NAME|count(1)|\n",
            "+-----------------+--------+\n",
            "|         Anguilla|       1|\n",
            "|           Russia|       1|\n",
            "|         Paraguay|       1|\n",
            "|          Senegal|       1|\n",
            "|           Sweden|       1|\n",
            "+-----------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataframe way"
      ],
      "metadata": {
        "id": "7QpwUn3Q54HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataFrameWay = flightData2015\\\n",
        "  .groupBy(\"DEST_COUNTRY_NAME\")\\\n",
        "  .count()"
      ],
      "metadata": {
        "id": "5FjkcjQ54bVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataFrameWay.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQAXZOxgOJnl",
        "outputId": "2a5e288a-dfef-401f-8b6c-caae46ba62ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+\n",
            "|DEST_COUNTRY_NAME|count|\n",
            "+-----------------+-----+\n",
            "|         Anguilla|    1|\n",
            "|           Russia|    1|\n",
            "|         Paraguay|    1|\n",
            "|          Senegal|    1|\n",
            "|           Sweden|    1|\n",
            "+-----------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sqlWay.explain()\n",
        "dataFrameWay.explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBM4W6ltOksH",
        "outputId": "ccdc0ce6-7134-47d2-f747-899d4157d8e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[DEST_COUNTRY_NAME#17], functions=[count(1)])\n",
            "   +- Exchange hashpartitioning(DEST_COUNTRY_NAME#17, 200), ENSURE_REQUIREMENTS, [plan_id=159]\n",
            "      +- HashAggregate(keys=[DEST_COUNTRY_NAME#17], functions=[partial_count(1)])\n",
            "         +- FileScan csv [DEST_COUNTRY_NAME#17] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/2015-summary.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string>\n",
            "\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[DEST_COUNTRY_NAME#17], functions=[count(1)])\n",
            "   +- Exchange hashpartitioning(DEST_COUNTRY_NAME#17, 200), ENSURE_REQUIREMENTS, [plan_id=172]\n",
            "      +- HashAggregate(keys=[DEST_COUNTRY_NAME#17], functions=[partial_count(1)])\n",
            "         +- FileScan csv [DEST_COUNTRY_NAME#17] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/2015-summary.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import max\n",
        "\n",
        "flightData2015.select(max(\"count\")).take(1)\n",
        "\n",
        "maxSql = spark.sql(\"\"\"\n",
        "SELECT DEST_COUNTRY_NAME, sum(count) as destination_total\n",
        "FROM flight_data_2015\n",
        "GROUP BY DEST_COUNTRY_NAME\n",
        "ORDER BY sum(count) DESC\n",
        "LIMIT 5\n",
        "\"\"\")\n",
        "\n",
        "maxSql.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqICFxBLO0Sj",
        "outputId": "e5b79ce5-5954-4fef-cfa0-973fc566a8ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------------+\n",
            "|DEST_COUNTRY_NAME|destination_total|\n",
            "+-----------------+-----------------+\n",
            "|    United States|           411352|\n",
            "|           Canada|             8399|\n",
            "|           Mexico|             7140|\n",
            "|   United Kingdom|             2025|\n",
            "|            Japan|             1548|\n",
            "+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql.functions import desc\n",
        "\n",
        "flightData2015\\\n",
        "  .groupBy(\"DEST_COUNTRY_NAME\")\\\n",
        "  .sum(\"count\")\\\n",
        "  .withColumnRenamed(\"sum(count)\", \"destination_total\")\\\n",
        "  .sort(desc(\"destination_total\"))\\\n",
        "  .limit(5)\\\n",
        "  .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sm-YVTUO5Ke",
        "outputId": "0843fb3f-7af7-4e7a-f019-ab1fbaccdb12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------------+\n",
            "|DEST_COUNTRY_NAME|destination_total|\n",
            "+-----------------+-----------------+\n",
            "|    United States|           411352|\n",
            "|           Canada|             8399|\n",
            "|           Mexico|             7140|\n",
            "|   United Kingdom|             2025|\n",
            "|            Japan|             1548|\n",
            "+-----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flightData2015\\\n",
        "  .groupBy(\"DEST_COUNTRY_NAME\")\\\n",
        "  .sum(\"count\")\\\n",
        "  .withColumnRenamed(\"sum(count)\", \"destination_total\")\\\n",
        "  .sort(desc(\"destination_total\"))\\\n",
        "  .limit(5)\\\n",
        "  .explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rckkDfxNO8ds",
        "outputId": "04f81a4c-5563-47ec-a24a-c967ca4c7768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- TakeOrderedAndProject(limit=5, orderBy=[destination_total#135L DESC NULLS LAST], output=[DEST_COUNTRY_NAME#17,destination_total#135L])\n",
            "   +- HashAggregate(keys=[DEST_COUNTRY_NAME#17], functions=[sum(count#19)])\n",
            "      +- Exchange hashpartitioning(DEST_COUNTRY_NAME#17, 200), ENSURE_REQUIREMENTS, [plan_id=310]\n",
            "         +- HashAggregate(keys=[DEST_COUNTRY_NAME#17], functions=[partial_sum(count#19)])\n",
            "            +- FileScan csv [DEST_COUNTRY_NAME#17,count#19] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/2015-summary.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,count:int>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can you follow the previouse examples to retrieve the count of males and females who are greater than 15 years old? ou can have the data here: https://drive.google.com/drive/folders/1ehWwunuAo7CE1Vk2JYkUnQMmxh5pph3C"
      ],
      "metadata": {
        "id": "PkU3FRIhQLyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "rRdr55tpPCc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUMaMWwVP0A6",
        "outputId": "89e85981-eabb-4743-8216-98077238ff87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|_c0|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "+---+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|  0|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
            "|  1|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
            "|  2|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
            "|  3|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
            "|  4|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
            "|  5|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|    0|          330877| 8.4583| NULL|       Q|\n",
            "|  6|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
            "|  7|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| NULL|       S|\n",
            "|  8|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| NULL|       S|\n",
            "|  9|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| NULL|       C|\n",
            "| 10|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
            "| 11|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
            "| 12|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| NULL|       S|\n",
            "| 13|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| NULL|       S|\n",
            "| 14|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| NULL|       S|\n",
            "| 15|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| NULL|       S|\n",
            "| 16|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| NULL|       Q|\n",
            "| 17|         18|       1|     2|Williams, Mr. Cha...|  male|NULL|    0|    0|          244373|   13.0| NULL|       S|\n",
            "| 18|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| NULL|       S|\n",
            "| 19|         20|       1|     3|Masselmani, Mrs. ...|female|NULL|    0|    0|            2649|  7.225| NULL|       C|\n",
            "+---+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#just an example with dataframe feature and groupby\n",
        "titanic.groupBy(\"Pclass\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y50Ti_PNP_AM",
        "outputId": "72511e6f-b003-4c23-d30b-2c65add6888d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|Pclass|count|\n",
            "+------+-----+\n",
            "|     3|  469|\n",
            "|     1|  201|\n",
            "|     ?|   49|\n",
            "|     2|  172|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}